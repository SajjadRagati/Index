{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SajjadRahati1/Index/blob/main/RQA_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfU15jAFgiPE"
      },
      "source": [
        "# Retrieval Question-Answering of NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDqE77xSj9Eu"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM8dgm1zuAfl"
      },
      "source": [
        "## Load from Json files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test3 = 'x'"
      ],
      "metadata": {
        "id": "_s-tzhrQB5wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAppzFUIghn9",
        "outputId": "dafb2b5b-a153-46f9-d0d0-aac82e97d2c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect to my drive for use dataset file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H7GdKwwf-sN"
      },
      "outputs": [],
      "source": [
        "# load files dataset\n",
        "import json\n",
        "with open('/content/drive/MyDrive/Dataset/RQA/SQuAD/dev-v2.0.json', 'r') as file:\n",
        "    data_dev = json.load(file)\n",
        "\n",
        "with open('/content/drive/MyDrive/Dataset/RQA/SQuAD/train-v2.0.json', 'r') as file:\n",
        "    data_train = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odOq75UVuHWp"
      },
      "source": [
        "## Extract Relevant Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx1UJfzAlq6P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# a function for get data and convert to a DataFrame\n",
        "def convert_to_Df(data:dict):\n",
        "  # Initialize lists to store the extracted data\n",
        "  questions = []\n",
        "  contexts = []\n",
        "  answers = []\n",
        "\n",
        "  # Parse the JSON data\n",
        "  for d in data['data']:\n",
        "    for parag in d['paragraphs']:\n",
        "      context = parag['context']\n",
        "\n",
        "      for qa in parag['qas']:\n",
        "        question = qa['question']\n",
        "        is_impossible = qa['is_impossible']\n",
        "\n",
        "        for answer in qa['answers']:\n",
        "          answer_text = answer['text']\n",
        "          answer_start = answer['answer_start']\n",
        "\n",
        "          # Append to lists\n",
        "          questions.append(question)\n",
        "          contexts.append(context)\n",
        "          answers.append((answer_text, answer_start, is_impossible))\n",
        "  # Create DataFrame\n",
        "  df = pd.DataFrame({\n",
        "      'question': questions,\n",
        "      'context': contexts,\n",
        "      'answer_text': [ans[0] for ans in answers],\n",
        "      'answer_start': [ans[1] for ans in answers],\n",
        "      'is_impossible': [ans[2] for ans in answers]\n",
        "  })\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKTxE3h2p17p"
      },
      "outputs": [],
      "source": [
        "df_dev = convert_to_Df(data_dev)\n",
        "df_train = convert_to_Df(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lUf4owpptg8-",
        "outputId": "d9a0eebd-d268-45e4-cdd3-3373b3f3b944"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                question  \\\n",
              "0               When did Beyonce start becoming popular?   \n",
              "1      What areas did Beyonce compete in when she was...   \n",
              "2      When did Beyonce leave Destiny's Child and bec...   \n",
              "3          In what city and state did Beyonce  grow up?    \n",
              "4             In which decade did Beyonce become famous?   \n",
              "...                                                  ...   \n",
              "86816  In what US state did Kathmandu first establish...   \n",
              "86817               What was Yangon previously known as?   \n",
              "86818  With what Belorussian city does Kathmandu have...   \n",
              "86819  In what year did Kathmandu create its initial ...   \n",
              "86820                      What is KMC an initialism of?   \n",
              "\n",
              "                                                 context  \\\n",
              "0      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "1      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "2      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "3      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "4      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "...                                                  ...   \n",
              "86816  Kathmandu Metropolitan City (KMC), in order to...   \n",
              "86817  Kathmandu Metropolitan City (KMC), in order to...   \n",
              "86818  Kathmandu Metropolitan City (KMC), in order to...   \n",
              "86819  Kathmandu Metropolitan City (KMC), in order to...   \n",
              "86820  Kathmandu Metropolitan City (KMC), in order to...   \n",
              "\n",
              "                       answer_text  answer_start  is_impossible  \n",
              "0                in the late 1990s           269          False  \n",
              "1              singing and dancing           207          False  \n",
              "2                             2003           526          False  \n",
              "3                   Houston, Texas           166          False  \n",
              "4                       late 1990s           276          False  \n",
              "...                            ...           ...            ...  \n",
              "86816                       Oregon           229          False  \n",
              "86817                      Rangoon           414          False  \n",
              "86818                        Minsk           476          False  \n",
              "86819                         1975           199          False  \n",
              "86820  Kathmandu Metropolitan City             0          False  \n",
              "\n",
              "[86821 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-738d5ea6-7b65-4fe1-a28d-f76a74349cfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>269</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>207</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>2003</td>\n",
              "      <td>526</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>166</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86816</th>\n",
              "      <td>In what US state did Kathmandu first establish...</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>229</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86817</th>\n",
              "      <td>What was Yangon previously known as?</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>Rangoon</td>\n",
              "      <td>414</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86818</th>\n",
              "      <td>With what Belorussian city does Kathmandu have...</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>Minsk</td>\n",
              "      <td>476</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86819</th>\n",
              "      <td>In what year did Kathmandu create its initial ...</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>1975</td>\n",
              "      <td>199</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86820</th>\n",
              "      <td>What is KMC an initialism of?</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>Kathmandu Metropolitan City</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86821 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-738d5ea6-7b65-4fe1-a28d-f76a74349cfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-738d5ea6-7b65-4fe1-a28d-f76a74349cfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-738d5ea6-7b65-4fe1-a28d-f76a74349cfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-791b410f-e5d9-49f4-940f-eb47289d06f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-791b410f-e5d9-49f4-940f-eb47289d06f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-791b410f-e5d9-49f4-940f-eb47289d06f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cee171ed-7fc2-4437-a429-2b5caab71e74\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cee171ed-7fc2-4437-a429-2b5caab71e74 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 86821,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86769,\n        \"samples\": [\n          \"Who used tuple calculus to show the functionality of databases?\",\n          \"What value system do Western scholars tend to use in analyzing societies?\",\n          \"What do live tiles do?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18877,\n        \"samples\": [\n          \"As of 21 February 2016[update] Spectre has grossed $879.3 million worldwide; $138.1 million of the takings have been generated from the UK market and $199.8 million from North America.\",\n          \"There are eight Island Courts and Lands Courts; appeals in relation to land disputes are made to the Lands Courts Appeal Panel. Appeals from the Island Courts and the Lands Courts Appeal Panel are made to the Magistrates Court, which has jurisdiction to hear civil cases involving up to $T10,000. The superior court is the High Court of Tuvalu as it has unlimited original jurisdiction to determine the Law of Tuvalu and to hear appeals from the lower courts. Sir Gordon Ward is the current Chief Justice of Tuvalu. Rulings of the High Court can be appealed to the Court of Appeal of Tuvalu. From the Court of Appeal there is a right of appeal to Her Majesty in Council, i.e., the Privy Council in London.\",\n          \"From 1966, Witness publications and convention talks built anticipation of the possibility that Christ's thousand-year reign might begin in late 1975 or shortly thereafter. The number of baptisms increased significantly, from about 59,000 in 1966 to more than 297,000 in 1974. By 1975, the number of active members exceeded two million. Membership declined during the late 1970s after expectations for 1975 were proved wrong. Watch Tower Society literature did not state dogmatically that 1975 would definitely mark the end, but in 1980 the Watch Tower Society admitted its responsibility in building up hope regarding that year.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 64763,\n        \"samples\": [\n          \"other animals early in evolution\",\n          \"$140.4 billion\",\n          \"Android devices, Apple's iPhone and iPad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 266,\n        \"min\": 0,\n        \"max\": 3126,\n        \"num_unique_values\": 1603,\n        \"samples\": [\n          217,\n          1056,\n          1163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_impossible\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5mj0YSMuN5U"
      },
      "source": [
        "## Preprocess the Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWtr_yLmuQsn",
        "outputId": "c7816abb-5f70-48ee-a215-c1d0294a18d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGSTHZMyw_NX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub7pgOvGuaLi"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Create function for tokenize dataFrames\n",
        "def preprocess_df(df:pd.DataFrame):\n",
        "  # Tokenize the text in the DataFrame\n",
        "  df['question_tokens'] = df['question'].apply(word_tokenize)\n",
        "  df['context_tokens'] = df['context'].apply(word_tokenize)\n",
        "  df['answer_tokens'] = df['answer_text'].apply(word_tokenize)\n",
        "\n",
        "  # Example of additional preprocessing (lowercasing)\n",
        "  df['question_tokens'] = df['question_tokens'].apply(lambda tokens: [token.lower() for token in tokens])\n",
        "  df['context_tokens'] = df['context_tokens'].apply(lambda tokens: [token.lower() for token in tokens])\n",
        "  df['answer_tokens'] = df['answer_tokens'].apply(lambda tokens: [token.lower() for token in tokens])\n",
        "\n",
        "  # Fit the tokenizer on the text data\n",
        "  tokenizer.fit_on_texts(df['context_tokens'] + df['question_tokens'])\n",
        "\n",
        "  # Convert tokens to sequences\n",
        "  df['context_seq'] = tokenizer.texts_to_sequences(df['context_tokens'])\n",
        "  df['question_seq'] = tokenizer.texts_to_sequences(df['question_tokens'])\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "def check_context_length(df_train,df_test):\n",
        "  # Pad sequences to ensure consistent input length\n",
        "  max_context_length_train = max(df_train['context_seq'].apply(len))\n",
        "  max_context_length_test = max(df_test['context_seq'].apply(len))\n",
        "  max_context_length = max(max_context_length_train, max_context_length_test)\n",
        "\n",
        "  max_question_length_train = max(df_train['question_seq'].apply(len))\n",
        "  max_question_length_test = max(df_test['question_seq'].apply(len))\n",
        "  max_question_length = max(max_question_length_train, max_question_length_test)\n",
        "\n",
        "  df_train['context_seq_padded'] = pad_sequences(df_train['context_seq'], maxlen=max_context_length, padding='post').tolist()\n",
        "  df_test['context_seq_padded'] = pad_sequences(df_test['context_seq'], maxlen=max_context_length, padding='post').tolist()\n",
        "\n",
        "  df_train['question_seq_padded'] = pad_sequences(df_train['question_seq'], maxlen=max_question_length, padding='post').tolist()\n",
        "  df_test['question_seq_padded'] = pad_sequences(df_test['question_seq'], maxlen=max_question_length, padding='post').tolist()\n",
        "\n",
        "  return df_train, df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUJLWLgIuxmW"
      },
      "outputs": [],
      "source": [
        "df_dev = preprocess_df(df_dev)\n",
        "df_train = preprocess_df(df_train)\n",
        "df_train, df_dev = check_context_length(df_train, df_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBlN0KjvwEsE"
      },
      "source": [
        "# Create model with LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lxRQuKOwf2n"
      },
      "source": [
        "## Prepare the Data for the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAl2Z-ihv5FT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def prepare_data(df):\n",
        "  # Prepare input arrays\n",
        "  X_context = np.array(df['context_seq_padded'].tolist())\n",
        "  X_question = np.array(df['question_seq_padded'].tolist())\n",
        "  y_start = np.array(df['answer_start'].tolist())\n",
        "  return (X_context, X_question, y_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTp7RXwVyYY5"
      },
      "outputs": [],
      "source": [
        "X_context_train, X_question_train, y_start_train = prepare_data(df_train)\n",
        "X_context_val, X_question_val, y_start_val = prepare_data(df_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnf39Mcqy_iw"
      },
      "source": [
        "## Define the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VYn2XQ_yigs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnvAhLBKzKa2"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 128\n",
        "lstm_units = 64\n",
        "# باتوجه به پدینگی که داده ایم پس مکس برای ما برابر با همین مقدار سایز این ستون است\n",
        "max_context_length = len(df_train['context_seq_padded'][0])\n",
        "max_question_length = len(df_train['question_seq_padded'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzIldEr2As0Y",
        "outputId": "8f2ecc93-62b6-4b09-e246-16e841355bed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(766, 60)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "max_context_length,max_question_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc8xYCFBzNBE"
      },
      "outputs": [],
      "source": [
        "# Input layers\n",
        "context_input = Input(shape=(max_context_length,), name='context_input')\n",
        "question_input = Input(shape=(max_question_length,), name='question_input')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPFqD1xHz7ZY"
      },
      "outputs": [],
      "source": [
        "# Embedding layers\n",
        "embedding = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim)\n",
        "\n",
        "context_embedding = embedding(context_input)\n",
        "question_embedding = embedding(question_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op7gefcRz_Lb"
      },
      "outputs": [],
      "source": [
        "# LSTM layers\n",
        "context_lstm = LSTM(lstm_units, return_sequences=False)(context_embedding)\n",
        "question_lstm = LSTM(lstm_units, return_sequences=False)(question_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7fgsBLr0B7R"
      },
      "outputs": [],
      "source": [
        "# Concatenate the outputs of the LSTM layers\n",
        "merged = Concatenate()([context_lstm, question_lstm])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyJ5GZuz0EQk"
      },
      "outputs": [],
      "source": [
        "# Dense layers for prediction\n",
        "dense = Dense(128, activation='relu')(merged)\n",
        "output = Dense(1, activation='linear')(dense)  # Predicting the start index of the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtgdYget0Gaf"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = Model(inputs=[context_input, question_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVhtN72u0Iq_",
        "outputId": "cda6e521-7a5a-445e-f9b8-59032f31e13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " context_input (InputLayer)  [(None, 766)]                0         []                            \n",
            "                                                                                                  \n",
            " question_input (InputLayer  [(None, 60)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)       multiple                     1360179   ['context_input[0][0]',       \n",
            "                                                          2          'question_input[0][0]']      \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 64)                   49408     ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 64)                   49408     ['embedding[1][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128)                  0         ['lstm[0][0]',                \n",
            "                                                                     'lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  16512     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13717249 (52.33 MB)\n",
            "Trainable params: 13717249 (52.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A583kQn0Y7u"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i1CE4zx0att",
        "outputId": "94528762-26d1-495c-8778-073a39d0d6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2714/2714 [==============================] - 2761s 1s/step - loss: 73772.0938 - accuracy: 1.3822e-04 - val_loss: 85928.2969 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "2714/2714 [==============================] - 2784s 1s/step - loss: 71039.7969 - accuracy: 1.0366e-04 - val_loss: 86220.9297 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "2714/2714 [==============================] - 2724s 1s/step - loss: 71043.0312 - accuracy: 1.0366e-04 - val_loss: 86047.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "2714/2714 [==============================] - 2726s 1s/step - loss: 71025.5000 - accuracy: 1.0366e-04 - val_loss: 86139.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "2033/2714 [=====================>........] - ETA: 10:50 - loss: 71498.5781 - accuracy: 9.2228e-05"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_context_train, X_question_train],\n",
        "    y_start_train,\n",
        "    validation_data=([X_context_val, X_question_val], y_start_val),\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")\n",
        "#یک بار اینو زدم فعلا دیگه ترین نمیکنم بریم بعدی"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IreBwzK1Asr"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = model\n",
        "lstm_history = history"
      ],
      "metadata": {
        "id": "9Xv3dMaE_wHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-3QBiJT1Cox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fa08da-44a2-4a47-e7d7-8db96fde03bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "635/635 [==============================] - 100s 158ms/step - loss: 86175.7344 - accuracy: 0.0000e+00\n",
            "Validation Loss: 86175.734375\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([X_context_val, X_question_val], y_start_val)\n",
        "print(f'Validation Loss: {loss}')\n",
        "print(f'Validation Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c0TAVGH5i4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea35fed-fb6d-4c40-ceeb-f6af937e1de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "base_address_file = '/content/drive/MyDrive/Dataset/RQA/SQuAD/'\n",
        "# Save the entire model to a file\n",
        "model.save(base_address_file + 'qa_model.h5')\n",
        "\n",
        "# Save the history to a file\n",
        "with open(base_address_file + 'training_history.pkl', 'wb') as file:\n",
        "    pickle.dump(history.history, file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "base_address_file = '/content/drive/MyDrive/Dataset/RQA/SQuAD/'"
      ],
      "metadata": {
        "id": "TimhD94Qe-JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_C61q616WYM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# # Download the model file\n",
        "# files.download('qa_model.h5')\n",
        "\n",
        "# # Download the training history file\n",
        "# files.download('training_history.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model with Transformer"
      ],
      "metadata": {
        "id": "rRc09zmn_WT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "Ussm8oFM_jDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "M4cvBOa9_hUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec03325-7c4b-4ab9-c5ae-815ece230db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Transformer"
      ],
      "metadata": {
        "id": "rktv_T_X_yaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['context'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "x6hkf6T8Hp3j",
        "outputId": "cc9b6f60-9a25-4553-b244-e2b3396f6d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Transformer Model"
      ],
      "metadata": {
        "id": "shefwBNFsL3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, Dense, LayerNormalization, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "uBv_Qzd4sCze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 128\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "VSEFkq2dsJF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Transformer block"
      ],
      "metadata": {
        "id": "CNYhZGlWsS1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer block\n",
        "def transformer_block(inputs, num_heads, ff_dim, dropout_rate):\n",
        "    # Multi-head self-attention\n",
        "    attention_output = MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embedding_dim\n",
        "    )(inputs, inputs)\n",
        "    attention_output = Dropout(dropout_rate)(attention_output)\n",
        "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ff_output = Dense(ff_dim, activation='relu')(attention_output)\n",
        "    ff_output = Dense(embedding_dim)(ff_output)\n",
        "    ff_output = Dropout(dropout_rate)(ff_output)\n",
        "    ff_output = LayerNormalization(epsilon=1e-6)(ff_output)\n",
        "\n",
        "    return ff_output"
      ],
      "metadata": {
        "id": "yA0hsxZcsaTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Transformer block to both context and question embeddings\n",
        "context_transformer = transformer_block(context_embedding, num_heads, ff_dim, dropout_rate)\n",
        "question_transformer = transformer_block(question_embedding, num_heads, ff_dim, dropout_rate)"
      ],
      "metadata": {
        "id": "QqZel-D2sdzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the dimensionality by taking the mean of all tokens (pooling)\n",
        "context_pooled = tf.reduce_mean(context_transformer, axis=1)\n",
        "question_pooled = tf.reduce_mean(question_transformer, axis=1)"
      ],
      "metadata": {
        "id": "PfiJe-lQsf3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the outputs of the Transformer blocks\n",
        "merged = Concatenate()([context_pooled, question_pooled])\n",
        "\n",
        "# Dense layers for prediction\n",
        "# dense = Dense(128, activation='relu')(merged)\n",
        "dense = Dense(64, activation='relu')(merged)\n",
        "output = Dense(1, activation='linear')(dense)  # Predicting the start index of the answer\n"
      ],
      "metadata": {
        "id": "DiE6prbTskEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model_transformer = Model(inputs=[context_input, question_input], outputs=output)\n",
        "model_transformer.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "e9BiqlTOsqhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_transformer.summary()"
      ],
      "metadata": {
        "id": "fissqCx2srec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "JGjeHH1csr8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history_transformer = model_transformer.fit(\n",
        "    [X_context_train, X_question_train],\n",
        "    y_start_train,\n",
        "    validation_data=([X_context_val, X_question_val], y_start_val),\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJks_WeWII0l",
        "outputId": "c7a027ea-ab92-4752-dda1-9cc8d973bbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " context_input (InputLayer)  [(None, 766)]                0         []                            \n",
            "                                                                                                  \n",
            " question_input (InputLayer  [(None, 60)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)       multiple                     1360179   ['context_input[0][0]',       \n",
            "                                                          2          'question_input[0][0]']      \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 766, 128)             527488    ['embedding[0][0]',           \n",
            " iHeadAttention)                                                     'embedding[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 60, 128)              527488    ['embedding[1][0]',           \n",
            " ltiHeadAttention)                                                   'embedding[1][0]']           \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 766, 128)             0         ['multi_head_attention[0][0]']\n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 60, 128)              0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 766, 128)             256       ['dropout[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 60, 128)              256       ['dropout_2[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 766, 128)             16512     ['layer_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 60, 128)              16512     ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 766, 128)             16512     ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 60, 128)              16512     ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 766, 128)             0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 60, 128)              0         ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 766, 128)             256       ['dropout_1[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 60, 128)              256       ['dropout_3[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpL  (None, 128)                  0         ['layer_normalization_1[0][0]'\n",
            " ambda)                                                             ]                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_1 (TFO  (None, 128)                  0         ['layer_normalization_3[0][0]'\n",
            " pLambda)                                                           ]                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 256)                  0         ['tf.math.reduce_mean[0][0]', \n",
            " )                                                                   'tf.math.reduce_mean_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 128)                  32896     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 1)                    129       ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14756865 (56.29 MB)\n",
            "Trainable params: 14756865 (56.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "1667/2714 [=================>............] - ETA: 3:50:09 - loss: 73047.4531 - accuracy: 7.4985e-05"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Model"
      ],
      "metadata": {
        "id": "2AtORXVDBV08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a file\n",
        "model_transformer.save_pretrained(base_address_file + 'qa_transformer_model.h5')\n",
        "# Save the history to a file\n",
        "with open(base_address_file + 'training_transformer_history.pkl', 'wb') as file:\n",
        "    pickle.dump(history_transformer.history, file)"
      ],
      "metadata": {
        "id": "h0CNmbUqBVcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# بررسی دو مدل با معیار های ارزیابی"
      ],
      "metadata": {
        "id": "NRmtM4aACTRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Evaluation Functions"
      ],
      "metadata": {
        "id": "67hcQqXACnSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Function to compute the Exact Match (EM) score\n",
        "def exact_match(pred, true):\n",
        "    return int(pred == true)\n",
        "\n",
        "# Function to compute the F1 score\n",
        "def f1_score_metric(pred, true):\n",
        "    pred_tokens = tokenizer.tokenize(pred)\n",
        "    true_tokens = tokenizer.tokenize(true)\n",
        "    common = set(pred_tokens) & set(true_tokens)\n",
        "    if len(common) == 0:\n",
        "        return 0\n",
        "    precision = len(common) / len(pred_tokens)\n",
        "    recall = len(common) / len(true_tokens)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, df_dev, tokenizer):\n",
        "    exact_matches = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for i, row in df_dev.iterrows():\n",
        "        context = row['context']\n",
        "        question = row['question']\n",
        "        true_answer = row['answer_text']\n",
        "\n",
        "        # Tokenize inputs\n",
        "        inputs = tokenizer(\n",
        "            context,\n",
        "            question,\n",
        "            truncation='only_first',\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors='tf'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "\n",
        "        # Predict the start position of the answer\n",
        "        start_logits = model.predict([input_ids, attention_mask, token_type_ids])[0]\n",
        "        start_index = np.argmax(start_logits)\n",
        "\n",
        "        # Decode the predicted answer\n",
        "        pred_answer = tokenizer.decode(input_ids[0][start_index:start_index+10], skip_special_tokens=True)\n",
        "\n",
        "        # Calculate metrics\n",
        "        exact_matches.append(exact_match(pred_answer, true_answer))\n",
        "        f1_scores.append(f1_score_metric(pred_answer, true_answer))\n",
        "\n",
        "    em_score = np.mean(exact_matches)\n",
        "    f1_score_avg = np.mean(f1_scores)\n",
        "\n",
        "    return em_score, f1_score_avg\n"
      ],
      "metadata": {
        "id": "gabTSeorChDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the LSTM Model"
      ],
      "metadata": {
        "id": "SN0-x5KUDAaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dev data for LSTM model\n",
        "X_context_dev = np.array(df_dev['context_seq_padded'].tolist())\n",
        "X_question_dev = np.array(df_dev['question_seq_padded'].tolist())\n",
        "y_start_dev = np.array(df_dev['answer_start'].tolist())\n",
        "\n",
        "# Predict the start positions\n",
        "start_preds = model_lstm.predict([X_context_dev, X_question_dev])\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "exact_matches_lstm = []\n",
        "f1_scores_lstm = []\n",
        "\n",
        "for i, pred in enumerate(start_preds):\n",
        "    start_index_pred = np.argmax(pred)\n",
        "    true_answer = df_dev.iloc[i]['answer_text']\n",
        "    context_tokens = df_dev.iloc[i]['context_tokens']\n",
        "    pred_answer_tokens = context_tokens[start_index_pred:start_index_pred+len(tokenizer.tokenize(true_answer))]\n",
        "    pred_answer = \" \".join(pred_answer_tokens)\n",
        "\n",
        "    exact_matches_lstm.append(exact_match(pred_answer, true_answer))\n",
        "    f1_scores_lstm.append(f1_score_metric(pred_answer, true_answer))\n",
        "\n",
        "em_score_lstm = np.mean(exact_matches_lstm)\n",
        "f1_score_avg_lstm = np.mean(f1_scores_lstm)\n",
        "\n",
        "print(f'LSTM Model - Exact Match (EM) Score: {em_score_lstm}')\n",
        "print(f'LSTM Model - F1 Score: {f1_score_avg_lstm}')\n"
      ],
      "metadata": {
        "id": "OE5kHEO1DCf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Transformer Model"
      ],
      "metadata": {
        "id": "-UoFRkusDJTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dev data for Transformer model\n",
        "X_context_dev = np.array(df_dev['context_seq_padded'].tolist())\n",
        "X_question_dev = np.array(df_dev['question_seq_padded'].tolist())\n",
        "y_start_dev = np.array(df_dev['answer_start'].tolist())\n",
        "\n",
        "# Predict the start positions\n",
        "start_preds = model_transformer.predict([X_context_dev, X_question_dev])\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "exact_matches_transformer = []\n",
        "f1_scores_transformer = []\n",
        "\n",
        "for i, pred in enumerate(start_preds):\n",
        "    start_index_pred = np.argmax(pred)\n",
        "    true_answer = df_dev.iloc[i]['answer_text']\n",
        "    context_tokens = df_dev.iloc[i]['context_tokens']\n",
        "    pred_answer_tokens = context_tokens[start_index_pred:start_index_pred+len(tokenizer.tokenize(true_answer))]\n",
        "    pred_answer = \" \".join(pred_answer_tokens)\n",
        "\n",
        "    exact_matches_transformer.append(exact_match(pred_answer, true_answer))\n",
        "    f1_scores_transformer.append(f1_score_metric(pred_answer, true_answer))\n",
        "\n",
        "em_score_transformer = np.mean(exact_matches_transformer)\n",
        "f1_score_avg_transformer = np.mean(f1_scores_transformer)\n",
        "\n",
        "print(f'Transformer Model - Exact Match (EM) Score: {em_score_transformer}')\n",
        "print(f'Transformer Model - F1 Score: {f1_score_avg_transformer}')"
      ],
      "metadata": {
        "id": "m3Aqi24KuT2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Evaluate BERT model\n",
        "# em_score_bert, f1_score_avg_bert = evaluate_model(model_bert, df_dev, tokenizer)\n",
        "\n",
        "# print(f'BERT Model - Exact Match (EM) Score: {em_score_bert}')\n",
        "# print(f'BERT Model - F1 Score: {f1_score_avg_bert}')"
      ],
      "metadata": {
        "id": "TP49GV-HDLiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## show with plt"
      ],
      "metadata": {
        "id": "vJI10H36D-W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the scores\n",
        "metrics = ['Exact Match (EM)', 'F1 Score']\n",
        "lstm_scores = [em_score_lstm, f1_score_avg_lstm]\n",
        "transformer_scores = [em_score_transformer, f1_score_avg_transformer]\n",
        "\n",
        "# Define the position of the bars on the x-axis\n",
        "x = np.arange(len(metrics))\n",
        "\n",
        "# Define the width of the bars\n",
        "width = 0.35\n",
        "\n",
        "# Create the bar chart\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "bars1 = ax.bar(x - width/2, lstm_scores, width, label='LSTM Model')\n",
        "bars2 = ax.bar(x + width/2, transformer_scores, width, label='Transformer Model')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Performance Comparison of LSTM and Transformer Models')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "# Attach a text label above each bar in *bars*, displaying its height\n",
        "def autolabel(bars):\n",
        "    \"\"\"Attach a text label above each bar in *bars*, displaying its height.\"\"\"\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate('{}'.format(round(height, 2)),\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(bars1)\n",
        "autolabel(bars2)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KMTQUuP_EBlx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}